<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Pedro F da Costa" />

  
  
  
    
  
  <meta name="description" content="This post is presented in noteworthy - the journal blog.
Hi everybody! Today, we will continue the series about autoregressive models.
Summary  Autoregressive models — PixelCNN Modelling coloured images PixelCNN’s blind spot in the receptive field Fixing the blind spot — Gated PixelCNN Conditional generation with Gated PixelCNN Gated PixelCNN with cropped convolutions Improving performance — PixelCNN&#43;&#43; Improving sampling time — Fast PixelCNN&#43;&#43; Using attention mechanisms — PixelSNAIL Generating Diverse High-Fidelity Images — VQ-VAE 2  For each topic, we implemented the models that are available in this repository." />

  
  <link rel="alternate" hreflang="en-us" href="http://pedroferreiradacosta.github.io/post/auto_encoder2/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#4caf50" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.fdf1e04434c5a4fc6a943a003775415e.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154348233-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-154348233-2', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="http://pedroferreiradacosta.github.io/post/auto_encoder2/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Pedro F da Costa" />
  <meta property="og:url" content="http://pedroferreiradacosta.github.io/post/auto_encoder2/" />
  <meta property="og:title" content="Modelling Coloured Images | Pedro F da Costa" />
  <meta property="og:description" content="This post is presented in noteworthy - the journal blog.
Hi everybody! Today, we will continue the series about autoregressive models.
Summary  Autoregressive models — PixelCNN Modelling coloured images PixelCNN’s blind spot in the receptive field Fixing the blind spot — Gated PixelCNN Conditional generation with Gated PixelCNN Gated PixelCNN with cropped convolutions Improving performance — PixelCNN&#43;&#43; Improving sampling time — Fast PixelCNN&#43;&#43; Using attention mechanisms — PixelSNAIL Generating Diverse High-Fidelity Images — VQ-VAE 2  For each topic, we implemented the models that are available in this repository." /><meta property="og:image" content="http://pedroferreiradacosta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="http://pedroferreiradacosta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2021-04-19T22:04:02&#43;01:00"
      />
    
    <meta property="article:modified_time" content="2021-04-19T22:04:02&#43;01:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://pedroferreiradacosta.github.io/post/auto_encoder2/"
  },
  "headline": "Modelling Coloured Images",
  
  "datePublished": "2021-04-19T22:04:02+01:00",
  "dateModified": "2021-04-19T22:04:02+01:00",
  
  "author": {
    "@type": "Person",
    "name": "Walter Hugo Lopez Pinaya"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Pedro F da Costa",
    "logo": {
      "@type": "ImageObject",
      "url": "http://pedroferreiradacosta.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "This post is presented in noteworthy - the journal blog.\nHi everybody! Today, we will continue the series about autoregressive models.\nSummary  Autoregressive models — PixelCNN Modelling coloured images PixelCNN’s blind spot in the receptive field Fixing the blind spot — Gated PixelCNN Conditional generation with Gated PixelCNN Gated PixelCNN with cropped convolutions Improving performance — PixelCNN++ Improving sampling time — Fast PixelCNN++ Using attention mechanisms — PixelSNAIL Generating Diverse High-Fidelity Images — VQ-VAE 2  For each topic, we implemented the models that are available in this repository."
}
</script>

  

  

  

  





  <title>Modelling Coloured Images | Pedro F da Costa</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="a1599d8a67e24ed0b1a4e5d98861c593" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Pedro F da Costa</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Pedro F da Costa</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/media/resume.pdf"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Modelling Coloured Images</h1>

  
  <p class="page-subtitle">Extending generative models to the full-colour spectrum</p>
  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Walter Hugo Lopez Pinaya</span>, <span >
      Pedro F. da Costa</span>, <span >
      Jessica Dafflon</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Apr 19, 2021
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/deep-learning/">Deep Learning</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>This post is presented in <a href="https://blog.usejournal.com/modelling-coloured-images-acd0ebde0102" target="_blank" rel="noopener">noteworthy - the journal blog</a>.</p>
<p>Hi everybody! Today, we will continue the series about autoregressive models.</p>
<h2 id="summary"><strong>Summary</strong></h2>
<ol>
<li>Autoregressive models — PixelCNN</li>
<li>Modelling coloured images</li>
<li>PixelCNN’s blind spot in the receptive field</li>
<li>Fixing the blind spot — Gated PixelCNN</li>
<li>Conditional generation with Gated PixelCNN</li>
<li>Gated PixelCNN with cropped convolutions</li>
<li>Improving performance — PixelCNN++</li>
<li>Improving sampling time — Fast PixelCNN++</li>
<li>Using attention mechanisms — PixelSNAIL</li>
<li>Generating Diverse High-Fidelity Images — VQ-VAE 2</li>
</ol>
<p>For each topic, we implemented the models that are available in <a href="https://github.com/Mind-the-Pineapple/Autoregressive-models" target="_blank" rel="noopener">this repository</a>.</p>
<p>In our previous post, we described an Autoregressive model for grayscale images, which only have one channel. In this post, we will talk about how to model images with multiples channels, such as RGB images. Let’s start!</p>
<p>The code for this topic can be found <a href="https://github.com/Mind-the-Pineapple/Autoregressive-models" target="_blank" rel="noopener">in this link</a>.</p>
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>As we discussed in our previous post, autoregressive generative models generate data from the product of conditional distributions, meaning that they depend on the previous pixels. So, to train the PixelCNN, we need to impose an ordering on the pixels of the generated image (e.g., from top to bottom and from left to right). To hide “future” pixels in convolutional operations, we mask the convolutional layers to ignore the information coming after the already predicted pixels. The first layer of the model should not have access to the pixel of interest of the input image, so we zero out the central pixel in the mask (we call this Mask A). But in the subsequent layers, the central pixel in the mask is already ignoring the pixel of interest of the input image, so it shouldn’t be zeroed out, so we use a Mask B. When dealing with images with more than one channel, such as coloured images which have three colour channels, which masks should we be using?</p>
<h2 id="coloured-images"><strong>Coloured Images</strong></h2>
<p>Coloured images are composed of three channels, Red, Green and Blue (RGB). The different colour channels can also be called sub-pixels. Each sub-pixel is not independent of the others as they compose a congruent image when combined. It is, therefore, necessary to order the sub-pixels so that we can process them sequentially and account for previous sub-pixels when predicting the next one, just as we do for the pixels. The masks need to be constructed to ensure that the prediction of a pixel is not a function of its input value.</p>
<p><img src="image1.png" alt="Image1"></p>
<p>Following the original paper, we choose to order the sub-pixels from R → G → B. In the first convolutional layer, we use Mask A where the R channel will have only access to the information of the previous pixels, which we call context, the G channel will have access to the context and the R channel, and finally, the B channel will have access to the context and both R and G channel. In the following convolutional layers, the central pixel of the previous convolutional layer has not ‘seen’ the input’s central pixel. So, the central sub-pixel does not need to be zeroed out. This means that in Mask B, the R channel has access to the context and the previous layer’s R channel. The G channel has access to the context plus the R and G channel and the B channel will have access to the context and the three channels.</p>
<p><img src="image2.png" alt="Image2"></p>
<p>Here we present a snippet showing how to build the masks for images with more than one channel. When the mask is connecting a channel of the current layer (i) that is a later order channel than the previous layer channel (j) and we zero out the central pixel. For mask A, we also zero out the central pixel when the current layer is connecting the same channel in the previous layer.</p>
<p>The network architecture we used is similar to the one presented for one-channel generative models, following Oord et al. 2016 implementation with 15 residual blocks and was presented on our <a href="https://towardsdatascience.com/autoregressive-models-pixelcnn-e30734ede0c1" target="_blank" rel="noopener">first blog post</a>.</p>
<h2 id="inference"><strong>Inference</strong></h2>
<p>When we are inferring coloured images, we have to predict three times more values than for one-channel images. This makes training the model more challenging. Here we trained our PixelCNN using the CIFAR10 dataset, so following Andrej Karpathy’s <a href="http://karpathy.github.io/2019/04/25/recipe/" target="_blank" rel="noopener">recipe for training neural networks</a>, we started by overfitting the model to the first two training set images.</p>
<p><img src="image3.png" alt="Image3"></p>
<p>So far, so good. After 10 epochs the model had already learned to mimic exactly the training set. But when we try to predict the next pixels of an occluded image that the model hasn’t seen yet, it does a poor job of completing the picture. This is expected as the model only learned to replicate the two examples it was shown.</p>
<p><img src="image4.png" alt="Image4"></p>
<p>Next, we trained our PixelCNN for 20 epochs using 50000 training images example to make our model learn the natural images.</p>
<p><img src="image5.png" alt="Image5"></p>
<p>Now our results were less than brilliant. Despite generating interesting landscapes, they don’t seem to be learning the structure of the natural images they were trained on.</p>
<p>In future posts, we are going to explore reasons behind the ineffectiveness — like the receptive field’s blind spot, and we are going to learn new techniques to improve on the quality of the generated images. Until then, we can simplify the problem by quantising the CIFAR10 images from their original 256 intensity values per sub-pixel to just 8 intensity values per sub-pixel. We trained the same model for 20 epochs and show how the generated image is evolving along epochs.</p>
<p><img src="image6.png" alt="Image6"></p>
<p>The images generated in the final epochs already has a natural combination of colours. It also does not look like images in the training data, so it is learning the data manifold distribution. We can now see what images the model generates and how it predicts occluded images, just as in the previous case.</p>
<p><img src="image7.png" alt="Image7"></p>
<p><img src="image8.png" alt="Image8"></p>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>It’s a challenge to train a PixelCNN to predict coloured figures. Although reducing the number of pixel intensity levels from 256 to 8 improved the results, the generated images were still not ideal. We briefly mentioned during the text that the performance could be improved by fixing the blind spot problem. So in the next two blog post, we will first introduce what is the blind spot and then we will show how we can fix it. So, stay tuned!</p>
<h2 id="references"><strong>References</strong></h2>
<ul>
<li><a href="http://bjlkeng.github.io/posts/pixelcnn/">http://bjlkeng.github.io/posts/pixelcnn/</a></li>
<li><a href="https://github.com/bjlkeng/sandbox/blob/master/notebooks/pixel_cnn/pixelcnn_helpers.py">https://github.com/bjlkeng/sandbox/blob/master/notebooks/pixel_cnn/pixelcnn_helpers.py</a></li>
<li><a href="http://sergeiturukin.com/2017/02/22/pixelcnn.html">http://sergeiturukin.com/2017/02/22/pixelcnn.html</a></li>
<li><a href="https://github.com/rampage644/wavenet/blob/master/wavenet/models.py">https://github.com/rampage644/wavenet/blob/master/wavenet/models.py</a></li>
<li><a href="https://github.com/tensorflow/magenta/blob/master/magenta/reviews/pixelrnn.md">https://github.com/tensorflow/magenta/blob/master/magenta/reviews/pixelrnn.md</a></li>
</ul>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/deep-learning/">Deep Learning</a>
  
  <a class="badge badge-light" href="/tag/autoregressive/">Autoregressive</a>
  
  <a class="badge badge-light" href="/tag/pixelcnn/">PixelCNN</a>
  
  <a class="badge badge-light" href="/tag/generative-models/">generative models</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=http://pedroferreiradacosta.github.io/post/auto_encoder2/&amp;text=Modelling%20Coloured%20Images" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=http://pedroferreiradacosta.github.io/post/auto_encoder2/&amp;t=Modelling%20Coloured%20Images" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Modelling%20Coloured%20Images&amp;body=http://pedroferreiradacosta.github.io/post/auto_encoder2/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=http://pedroferreiradacosta.github.io/post/auto_encoder2/&amp;title=Modelling%20Coloured%20Images" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Modelling%20Coloured%20Images%20http://pedroferreiradacosta.github.io/post/auto_encoder2/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=http://pedroferreiradacosta.github.io/post/auto_encoder2/&amp;title=Modelling%20Coloured%20Images" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    




  
    




  
    




  














  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/auto_encoder/">Autoregressive Models — PixelCNN</a></li>
      
      <li><a href="/project/bayesian-optimization/">Building new methods with Bayesian Optimization</a></li>
      
      <li><a href="/project/normative-modelling/">Normative Modelling in Psychiatry</a></li>
      
      <li><a href="/publication/da-costa-2018/">Application of Artificial Neural Networks for modelling cognitive dimensions</a></li>
      
      <li><a href="/publication/pinaya-2020/">Normative modelling using deep autoencoders: a multi-cohort study on mild cognitive impairment and Alzheimer&#39;s disease</a></li>
      
    </ul>
  </div>
  





  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  <p class="powered-by">
    © 2021 Pedro F da Costa
  </p>

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b61a8f62b6e5c0cd322c8158c5b5dfb6.js"></script>

    






</body>
</html>
